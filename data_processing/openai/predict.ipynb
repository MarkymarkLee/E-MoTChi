{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/all_sentences.json\", encoding='utf-8') as f:\n",
    "    sentences = json.load(f)\n",
    "\n",
    "\n",
    "with open(\"../data/gpt_dataset.json\", encoding='utf-8') as f:\n",
    "    gpt_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üêÇüëÄüèÄüì±'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from secret import OPENAI_API_KEY\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def predict(sentence):\n",
    "    model_id = \"ft:gpt-3.5-turbo-0613:personal::8YaCVIRe\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an emoji translation expert, specializing in understanding and translating emoji sentences. Your primary role is to translate emoji sequences into Traditional Chinese, taking into account homophonic nuances of the language. You should also be able to translate Chinese sentences to emoji. Your knowledge extends to understanding the cultural and contextual meanings of emojis, ensuring accurate and relevant translations.\"},\n",
    "            {\"role\": \"user\", \"content\": sentence}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "predict(\"ÈÄôÈ∫ºÁâõÔºåÊàëË¶ÅÂéªÈóúÊ≥®‰ªñ‰∏Ä‰∏ã„ÄÇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4679it [30:15,  2.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3720"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "new = []\n",
    "count = 0\n",
    "for i,s in tqdm(enumerate(sentences)):\n",
    "    dd = None\n",
    "    for d in gpt_dataset:\n",
    "        if d['id'] == i:\n",
    "            dd = d\n",
    "            break\n",
    "    if dd is None:\n",
    "        count += 1\n",
    "        p = predict(s)\n",
    "        new.append({\"id\": i, \"chinese\": s, \"emoji\": p})\n",
    "    else:\n",
    "        new.append(dd)\n",
    "with open(\"../data/gpt_dataset.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(new, f, ensure_ascii=False, indent=4)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
